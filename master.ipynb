{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Crypto market capitalization forecast based on S&P 500.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Abstract**\n",
    "   Abstract here. Give an executive summary of your project: goal, methods, results, conclusions. Usually no more than 200 words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "Here you have to explain the problem that you are solving. Explain why it is important, and what are the main challenges. Mention previous attempts (add papers as references) to solve it. Mainly focus on the techniques closely related to our approach. Briefly describe your approach and explain why it is promising for solving the addressed problem. Mention the dataset and the main results achieved.\n",
    "\n",
    "In this section, you can add **text** and **figures**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Methodology**\n",
    "Describe the important steps you took to achieve your goal. Focus more on the most important steps (preprocessing, extra features, model aspects) that turned out to be important. Mention the original aspects of the project and state how they relate to existing work.\n",
    "\n",
    "In this section, you can add **text** and **figures**. For instance, it is strongly suggested to add a picture of the best machine learning model that you implemented to solve your problem (and describe it).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in our methodology involved preprocessing the raw data from 2 sources: Kaggle and CoinCodex. We will be using the Kaggle data for everything that is related to the S&P500, and CoinCodex for everything related crypto. For the cryptocurrency data, we focused on key features such as Date, Volume, and Marketcap. Similarly, for the S&P500 data, we retained relevant columns like Date, Open, High, Low, Close, Volume, and additional info regarding the fear index (VIX). The datasets were cleaned to handle missing values, if any, unwanted data and the Date columns were standardized to ensure compatibility for merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Let's import the necessary libraries that we need for the project and define some constants!\n",
    "Run the code below...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'Data/'\n",
    "STOCK_DATA_PATH_RAW = 'Data/StockData/RawData/'\n",
    "STOCK_DATA_PATH_PROCESSED = 'Data/StockData/preProcessedData/'\n",
    "CRYPTO_DATA_PATH_RAW = 'Data/CryptoData/RawData/'\n",
    "CRYPTO_DATA_PATH_PROCESSED = 'Data/CryptoData/PreProcessedData/'\n",
    "KAGGLE_DATA_PATH = 'Data/KaggleData/'\n",
    "START_DATE = '2018-01-18'\n",
    "END_DATE = '2025-04-04'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the libraries imported, we can now load the S&P500 data, and an example of crypto data to take a look at the first few rows along with some additional info by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Dataset ==> Min Date: 2017-01-03 00:00:00 / Max Date: 2025-04-04 00:00:00\n",
      "\n",
      "VIX Dataset ==> Min Date: 1990-01-02 00:00:00 / Max Date: 2025-04-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename: str, date_col: str, date_format: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a pandas DataFrame and parses the date column.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Name of the CSV file.\n",
    "        date_col (str): Name of the date column.\n",
    "        date_format (str): Format of the date in the CSV.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with parsed dates.\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(STOCK_DATA_PATH_RAW, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format=date_format)\n",
    "    return df\n",
    "\n",
    "stock_df = load_data('S&P500_Historical_Data.csv', 'Date', '%Y-%m-%d')\n",
    "vix_df = load_data('VIX_Historical_Data.csv', 'Date', '%m/%d/%Y')\n",
    "\n",
    "for name, df in zip([\"Stock\", \"VIX\"], [stock_df, vix_df]):\n",
    "    print(f\"\\n{name} Dataset ==> Min Date: {df['Date'].min()} / Max Date: {df['Date'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Change %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>5,074.08</td>\n",
       "      <td>5,292.14</td>\n",
       "      <td>5,292.14</td>\n",
       "      <td>5,069.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>5,396.52</td>\n",
       "      <td>5,492.74</td>\n",
       "      <td>5,499.53</td>\n",
       "      <td>5,390.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>5,670.97</td>\n",
       "      <td>5,580.76</td>\n",
       "      <td>5,695.31</td>\n",
       "      <td>5,571.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>5,633.07</td>\n",
       "      <td>5,597.53</td>\n",
       "      <td>5,650.57</td>\n",
       "      <td>5,558.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>5,611.85</td>\n",
       "      <td>5,527.91</td>\n",
       "      <td>5,627.56</td>\n",
       "      <td>5,488.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Price      Open      High       Low  Vol. Change %\n",
       "0 2025-04-04  5,074.08  5,292.14  5,292.14  5,069.90   NaN   -5.97%\n",
       "1 2025-04-03  5,396.52  5,492.74  5,499.53  5,390.83   NaN   -4.84%\n",
       "2 2025-04-02  5,670.97  5,580.76  5,695.31  5,571.48   NaN    0.67%\n",
       "3 2025-04-01  5,633.07  5,597.53  5,650.57  5,558.52   NaN    0.38%\n",
       "4 2025-03-31  5,611.85  5,527.91  5,627.56  5,488.73   NaN    0.55%"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-08</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Open   High    Low  Close\n",
       "0 1990-01-02  17.24  17.24  17.24  17.24\n",
       "1 1990-01-03  18.19  18.19  18.19  18.19\n",
       "2 1990-01-04  19.22  19.22  19.22  19.22\n",
       "3 1990-01-05  20.11  20.11  20.11  20.11\n",
       "4 1990-01-08  20.26  20.26  20.26  20.26"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-06</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>83533.45</td>\n",
       "      <td>83704.76</td>\n",
       "      <td>77296.39</td>\n",
       "      <td>78310.34</td>\n",
       "      <td>2.974769e+10</td>\n",
       "      <td>1.626852e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>2025-04-06</td>\n",
       "      <td>83769.12</td>\n",
       "      <td>84219.70</td>\n",
       "      <td>82384.97</td>\n",
       "      <td>83582.03</td>\n",
       "      <td>5.424886e+10</td>\n",
       "      <td>1.654110e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>83259.08</td>\n",
       "      <td>84676.27</td>\n",
       "      <td>81767.53</td>\n",
       "      <td>83879.86</td>\n",
       "      <td>6.263226e+10</td>\n",
       "      <td>1.654911e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>82259.03</td>\n",
       "      <td>83781.70</td>\n",
       "      <td>81307.75</td>\n",
       "      <td>83199.95</td>\n",
       "      <td>7.766843e+10</td>\n",
       "      <td>1.643472e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>85170.68</td>\n",
       "      <td>87898.01</td>\n",
       "      <td>82487.40</td>\n",
       "      <td>82548.31</td>\n",
       "      <td>5.237611e+10</td>\n",
       "      <td>1.688190e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Start         End      Open      High       Low     Close  \\\n",
       "0  2025-04-06  2025-04-07  83533.45  83704.76  77296.39  78310.34   \n",
       "1  2025-04-05  2025-04-06  83769.12  84219.70  82384.97  83582.03   \n",
       "2  2025-04-04  2025-04-05  83259.08  84676.27  81767.53  83879.86   \n",
       "3  2025-04-03  2025-04-04  82259.03  83781.70  81307.75  83199.95   \n",
       "4  2025-04-02  2025-04-03  85170.68  87898.01  82487.40  82548.31   \n",
       "\n",
       "         Volume    Market Cap  \n",
       "0  2.974769e+10  1.626852e+12  \n",
       "1  5.424886e+10  1.654110e+12  \n",
       "2  6.263226e+10  1.654911e+12  \n",
       "3  7.766843e+10  1.643472e+12  \n",
       "4  5.237611e+10  1.688190e+12  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_df = pd.read_csv(os.path.join(CRYPTO_DATA_PATH_RAW, 'BTC.csv'))\n",
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Crypto Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's now tackle our raw crypto data.  \n",
    "After some research and many hours of trying to find the best balance between variety of cryptos and the amount of data that can be used, I have decided to include 14 cryptos from the top 100 where the data stretches from 2018 to 2025.  \n",
    "\n",
    "Let us take a look at an example of crypto data that we have:\n",
    "\n",
    "**Note**: We have a CSV for every crypto. (14 CSVs total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us standardize our timeframe now. From all the CSVs we have, we can see that our range should be from 2018-1-18 to 2025-04-04 to match the maximum date of the stock market data and the minimum date of the crypto CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed!\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
    "processed_dfs = {}  # Dictionary to store processed DataFrames (key: symbol, value: DataFrame)\n",
    "\n",
    "for filename in os.listdir(CRYPTO_DATA_PATH_RAW):\n",
    "    try:\n",
    "        raw_path = os.path.join(CRYPTO_DATA_PATH_RAW, filename)\n",
    "        df = pd.read_csv(raw_path)\n",
    "        df['Start'] = pd.to_datetime(df['Start'])\n",
    "        df = df[df['Start'].isin(date_range)]\n",
    "        df = df.sort_values('Start')\n",
    "        \n",
    "        symbol = filename.split('.')[0]  # Extract symbol (e.g., 'BTC' from 'BTC.csv')\n",
    "        processed_dfs[symbol] = df # Store processed DataFrame in the dictionary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "print(\"All files processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now check for some missing values in the most interesting features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BNB:\n",
      "  ==> Missing/Invalid 'Volume' values: 0\n",
      "  ==> Missing/Invalid 'Market Cap' values: 133\n",
      "\n",
      "EOS:\n",
      "  ==> Missing/Invalid 'Volume' values: 0\n",
      "  ==> Missing/Invalid 'Market Cap' values: 133\n",
      "\n",
      "Check complete!\n"
     ]
    }
   ],
   "source": [
    "# Check for missing/invalid values (0, -1, or NaN) in key columns\n",
    "for symbol, df in processed_dfs.items():\n",
    "    invalid_volume = ((df['Volume'] == 0) | (df['Volume'] == -1) | (df['Volume'].isna())).sum()\n",
    "    invalid_market_cap = ((df['Market Cap'] == 0) | (df['Market Cap'] == -1) | (df['Market Cap'].isna())).sum()\n",
    "    \n",
    "    if invalid_volume > 0 or invalid_market_cap > 0:\n",
    "        print(f\"\\n{symbol}:\")\n",
    "        print(f\"  ==> Missing/Invalid 'Volume' values: {invalid_volume}\")\n",
    "        print(f\"  ==> Missing/Invalid 'Market Cap' values: {invalid_market_cap}\")\n",
    "\n",
    "print(\"\\nCheck complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the dataframes of each token, we can see that there are some data points of market cap data missing in BNB and EOS.  \n",
    "We will use data from kaggle to fill that in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB: Updated 133 market cap values\n",
      "EOS: Updated 133 market cap values\n",
      "\n",
      "Market caps updated!\n"
     ]
    }
   ],
   "source": [
    "def update_market_caps(processed_dfs, all_crypto_file):\n",
    "    all_crypto_df = pd.read_csv(all_crypto_file)\n",
    "    \n",
    "    for symbol, crypto_df in processed_dfs.items():\n",
    "        try:\n",
    "            crypto_df['Start'] = pd.to_datetime(crypto_df['Start'])\n",
    "            symbol_data = all_crypto_df[all_crypto_df['Symbol'] == symbol].copy()\n",
    "            symbol_data['Date'] = pd.to_datetime(symbol_data['Date'], format='%d-%m-%Y %H:%M')\n",
    "            \n",
    "            # Normalize dates for comparison\n",
    "            crypto_df['Start_date'] = crypto_df['Start'].dt.normalize()\n",
    "            symbol_data['Date_date'] = symbol_data['Date'].dt.normalize()\n",
    "            \n",
    "            # Map market caps by date\n",
    "            market_cap_dict = dict(zip(symbol_data['Date_date'], symbol_data['Marketcap']))\n",
    "            \n",
    "            # Update missing market caps\n",
    "            updated_count = 0\n",
    "            for index, row in crypto_df.iterrows():\n",
    "                if row['Market Cap'] in [0.0, -1.0]:\n",
    "                    start_date = row['Start_date']\n",
    "                    if start_date in market_cap_dict:\n",
    "                        crypto_df.at[index, 'Market Cap'] = market_cap_dict[start_date]\n",
    "                        updated_count += 1\n",
    "            \n",
    "            crypto_df.drop(columns=['Start_date'], inplace=True)\n",
    "            \n",
    "            if updated_count > 0:\n",
    "                print(f\"{symbol}: Updated {updated_count} market cap values\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "update_market_caps(processed_dfs, KAGGLE_DATA_PATH + 'All_Crypto.csv')\n",
    "print(\"\\nMarket caps updated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now our crypto data is complete within the time range of 2018 to 2025.  \n",
    "Let us now work on dropping the unwated features and making the merged crypto dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to Crypto.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge all DataFrames and add 'symbol' column\n",
    "merged_df = pd.concat(\n",
    "    [df.assign(symbol=symbol) for symbol, df in processed_dfs.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Drop unwanted columns and rename\n",
    "merged_df.drop(columns=['End', 'Low', 'High', 'Open', 'Close'], inplace=True)\n",
    "merged_df.rename(columns={'Start': 'Date', 'Market Cap': 'MarketCap'}, inplace=True)\n",
    "\n",
    "# Save the final merged file\n",
    "output_file = 'Crypto.csv'\n",
    "merged_df.to_csv(os.path.join(CRYPTO_DATA_PATH_PROCESSED, output_file), index=False)\n",
    "print(f\"Merged data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now aggregate the data to have the daily total Market Cap and Voume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data by date so that each date has the sum of market caps and volumes for all cryptocurrencies\n",
    "def aggregate_crypto_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates crypto data by date, summing 'Volume' and 'MarketCap',\n",
    "    and renames the columns for clarity.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with 'Date', 'Volume', and 'MarketCap' columns.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated DataFrame with 'Date', 'Crypto_Volume', and 'Crypto_Market_Cap'.\n",
    "    \"\"\"\n",
    "    aggregated_df = (\n",
    "        df.groupby('Date', as_index=False)\n",
    "        .agg({'Volume': 'sum', 'MarketCap': 'sum'})\n",
    "        .rename(columns={'Volume': 'Crypto_Volume', 'MarketCap': 'Crypto_Market_Cap'})\n",
    "    )\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data saved to Aggregated_Crypto.csv\n"
     ]
    }
   ],
   "source": [
    "crypto_df = aggregate_crypto_data(merged_df)\n",
    "crypto_df.to_csv(os.path.join(CRYPTO_DATA_PATH_PROCESSED, 'Aggregated_Crypto.csv'), index=False)\n",
    "print(\"Aggregated data saved to Aggregated_Crypto.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **S&P500 Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now process the stock market data.  \n",
    "We need to keep in mind that the stock market closes on the weekends. Thus, for the sake of this project, we will assume that the last available price (Friday’s) carries over to Saturday and Sunday since stock prices don’t change on weekends.  \n",
    "We will use Forward fill to accomplish this.  \n",
    "This will keep the dataset aligned with the crypto data. Also, it reflects the reality that stock prices remain unchanged on weekends.\n",
    "Same thing will be done to the VIX data frame as well.\n",
    "\n",
    "Let's define some helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_closed_weekends(df: pd.DataFrame, start_date: str, end_date: str, date_col: str = 'Date') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes S&P 500 data to:\n",
    "    1. Filter date range\n",
    "    2. Expand to include weekends\n",
    "    3. Forward-fill price columns\n",
    "    4. Set 'Change_%' to 0.0 on weekends\n",
    "    5. Ensure proper datetime format\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with market data\n",
    "        start_date: Start date (YYYY-MM-DD)\n",
    "        end_date: End date (YYYY-MM-DD)\n",
    "        date_col: Name of date column\n",
    "    \n",
    "    Returns:\n",
    "        Processed DataFrame with continuous daily data\n",
    "    \"\"\"\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    filtered_df = df[(df[date_col] >= start_date) & (df[date_col] <= end_date)].copy()\n",
    "    \n",
    "    full_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    if 'S&P500_Change_%' in filtered_df.columns:\n",
    "        filtered_df['S&P500_Change_%'] = (\n",
    "            filtered_df['S&P500_Change_%']\n",
    "            .astype(str)\n",
    "            .str.replace('%', '')\n",
    "            .replace('', '0')\n",
    "            .astype(float)\n",
    "        )\n",
    "    \n",
    "    reindexed_df = (\n",
    "        filtered_df\n",
    "        .set_index(date_col)\n",
    "        .reindex(full_dates)\n",
    "    )\n",
    "    \n",
    "    price_cols = [col for col in reindexed_df.columns if col != 'Change_%']\n",
    "    \n",
    "    reindexed_df[price_cols] = reindexed_df[price_cols].ffill()\n",
    "    \n",
    "    if 'S&P500_Change_%' in reindexed_df.columns:\n",
    "        reindexed_df['S&P500_Change_%'] = reindexed_df['S&P500_Change_%'].fillna(0.0)\n",
    "    \n",
    "    result = reindexed_df.reset_index().rename(columns={'index': date_col})\n",
    "    \n",
    "    result[date_col] = pd.to_datetime(result[date_col])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def preprocess_sp500(df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    df = df.drop(columns=['Vol.'], errors='ignore')\n",
    "    df['Open'] = df['Open'].str.replace(',', '').astype(float)\n",
    "    df['High'] = df['High'].str.replace(',', '').astype(float)\n",
    "    df['Low'] = df['Low'].str.replace(',', '').astype(float)\n",
    "    df['Price'] = df['Price'].str.replace(',', '').astype(float)\n",
    "    df = df.rename(columns={\n",
    "            'Open': 'S&P500_Open',\n",
    "            'High': 'S&P500_High',\n",
    "            'Low': 'S&P500_Low',\n",
    "            'Price': 'S&P500_Close',\n",
    "            'Change %': 'S&P500_Change_%'\n",
    "    })\n",
    "    \n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    processed = handle_closed_weekends(\n",
    "        df=df,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        date_col='Date'\n",
    "    )\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def preprocess_vix(df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.rename(columns={\n",
    "            'Open': 'VIX_Open',\n",
    "            'High': 'VIX_High',\n",
    "            'Low': 'VIX_Low',\n",
    "            'Close': 'VIX_Close'\n",
    "        })\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    df = (\n",
    "        df.set_index('Date')\n",
    "        .reindex(date_range)\n",
    "        .ffill()\n",
    "        .reset_index()\n",
    "        .rename(columns={'index': 'Date'})\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P500 dataset: 2018-01-18 00:00:00 to 2025-04-04 00:00:00 with 2634 rows\n",
      "Columns: ['Date', 'S&P500_Close', 'S&P500_Open', 'S&P500_High', 'S&P500_Low', 'S&P500_Change_%']\n",
      "\n",
      "VIX dataset: 2018-01-18 00:00:00 to 2025-04-04 00:00:00 with 2634 rows\n",
      "Columns: ['Date', 'VIX_Open', 'VIX_High', 'VIX_Low', 'VIX_Close']\n"
     ]
    }
   ],
   "source": [
    "# Process both datasets\n",
    "stock_df = preprocess_sp500(stock_df, START_DATE, END_DATE)\n",
    "vix_df = preprocess_vix(vix_df, START_DATE, END_DATE)\n",
    "\n",
    "# Print results\n",
    "print(f\"S&P500 dataset: {stock_df['Date'].min()} to {stock_df['Date'].max()} \"\n",
    "      f\"with {len(stock_df)} rows\")\n",
    "print(f\"Columns: {stock_df.columns.tolist()}\\n\")\n",
    "\n",
    "print(f\"VIX dataset: {vix_df['Date'].min()} to {vix_df['Date'].max()} \"\n",
    "      f\"with {len(vix_df)} rows\")\n",
    "print(f\"Columns: {vix_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed stock and VIX data saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the processed stock and VIX data\n",
    "stock_df.to_csv(os.path.join(STOCK_DATA_PATH_PROCESSED, 'S&P500.csv'), index=False)\n",
    "vix_df.to_csv(os.path.join(STOCK_DATA_PATH_PROCESSED, 'VIX.csv'), index=False)\n",
    "print(\"Processed stock and VIX data saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merging and Unification of the datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now that we have cleaned the data, we still have to unify our datasets into one before starting to play with models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>S&amp;P500_Close</th>\n",
       "      <th>S&amp;P500_Open</th>\n",
       "      <th>S&amp;P500_High</th>\n",
       "      <th>S&amp;P500_Low</th>\n",
       "      <th>S&amp;P500_Change_%</th>\n",
       "      <th>VIX_Open</th>\n",
       "      <th>VIX_High</th>\n",
       "      <th>VIX_Low</th>\n",
       "      <th>VIX_Close</th>\n",
       "      <th>Crypto_Volume</th>\n",
       "      <th>Crypto_Market_Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>2802.4</td>\n",
       "      <td>2805.8</td>\n",
       "      <td>2792.6</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>12.01</td>\n",
       "      <td>12.40</td>\n",
       "      <td>11.62</td>\n",
       "      <td>12.22</td>\n",
       "      <td>3.397555e+10</td>\n",
       "      <td>4.182316e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2802.6</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2798.1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>11.18</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.290271e+10</td>\n",
       "      <td>4.241106e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2802.6</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2798.1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>11.18</td>\n",
       "      <td>11.27</td>\n",
       "      <td>1.770756e+10</td>\n",
       "      <td>4.568364e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2802.6</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2798.1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>11.18</td>\n",
       "      <td>11.27</td>\n",
       "      <td>1.591606e+10</td>\n",
       "      <td>4.235859e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>2809.2</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>2808.1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11.59</td>\n",
       "      <td>11.62</td>\n",
       "      <td>10.84</td>\n",
       "      <td>11.03</td>\n",
       "      <td>1.512720e+10</td>\n",
       "      <td>4.032085e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  S&P500_Close  S&P500_Open  S&P500_High  S&P500_Low  \\\n",
       "0 2018-01-18        2798.0       2802.4       2805.8      2792.6   \n",
       "1 2018-01-19        2810.3       2802.6       2810.3      2798.1   \n",
       "2 2018-01-20        2810.3       2802.6       2810.3      2798.1   \n",
       "3 2018-01-21        2810.3       2802.6       2810.3      2798.1   \n",
       "4 2018-01-22        2833.0       2809.2       2833.0      2808.1   \n",
       "\n",
       "   S&P500_Change_%  VIX_Open  VIX_High  VIX_Low  VIX_Close  Crypto_Volume  \\\n",
       "0            -0.16     12.01     12.40    11.62      12.22   3.397555e+10   \n",
       "1             0.44     12.30     12.33    11.18      11.27   2.290271e+10   \n",
       "2             0.44     12.30     12.33    11.18      11.27   1.770756e+10   \n",
       "3             0.44     12.30     12.33    11.18      11.27   1.591606e+10   \n",
       "4             0.81     11.59     11.62    10.84      11.03   1.512720e+10   \n",
       "\n",
       "   Crypto_Market_Cap  \n",
       "0       4.182316e+11  \n",
       "1       4.241106e+11  \n",
       "2       4.568364e+11  \n",
       "3       4.235859e+11  \n",
       "4       4.032085e+11  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.merge(stock_df, vix_df, on='Date', how='inner')\n",
    "main_df = pd.merge(temp_df, crypto_df, on='Date', how='inner')\n",
    "main_df.to_csv(os.path.join(DATA_PATH, 'MainData.csv'), index=False)\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our main dataset, we can add meaningful features to it that will probably help with the training of the models.  \n",
    "Let's define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help model to learn seasonal or cyclic patterns\n",
    "def add_seasonal_features(df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds seasonal features to the DataFrame based on the date column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        date_col (str): The name of the date column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added seasonal features.\n",
    "    \"\"\"\n",
    "    df['Year'] = df[date_col].dt.year\n",
    "    df['Month'] = df[date_col].dt.month\n",
    "    df['Day'] = df[date_col].dt.day\n",
    "    df['DayOfWeek'] = df[date_col].dt.dayofweek\n",
    "    df['IsWeekend'] = df['DayOfWeek'] >= 5\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add rolling statistics\n",
    "def add_rolling_statistics(df: pd.DataFrame, window: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds rolling statistics to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        window (int): The rolling window size.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added rolling statistics.\n",
    "    \"\"\"\n",
    "    df['Market_Cap_MA'] = df['Crypto_Market_Cap'].rolling(window=window).mean()\n",
    "    df['Market_Cap_STD'] = df['Crypto_Market_Cap'].rolling(window=window).std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add lag features\n",
    "def add_lag_features(df: pd.DataFrame, lag: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds lag features to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        lag (int): The lag period.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added lag features.\n",
    "    \"\"\"\n",
    "    df['Lagged_Market_Cap'] = df['Crypto_Market_Cap'].shift(lag)\n",
    "    df['Lagged_VIX_Close'] = df['VIX_Close'].shift(lag)\n",
    "    df['Lagged_S&P500_Close'] = df['S&P500_Close'].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add crypto percent change\n",
    "def add_crypto_percent_change(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds percentage change for the Crypto_Market_Cap column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added percentage change feature.\n",
    "    \"\"\"\n",
    "    df['Crypto_Market_Cap_%'] = df['Crypto_Market_Cap'].pct_change() * 100\n",
    "    df['Crypto_Volume_Change_%'] = df['Crypto_Volume'].pct_change() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>S&amp;P500_Close</th>\n",
       "      <th>S&amp;P500_Open</th>\n",
       "      <th>S&amp;P500_High</th>\n",
       "      <th>S&amp;P500_Low</th>\n",
       "      <th>S&amp;P500_Change_%</th>\n",
       "      <th>VIX_Open</th>\n",
       "      <th>VIX_High</th>\n",
       "      <th>VIX_Low</th>\n",
       "      <th>VIX_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Market_Cap_MA</th>\n",
       "      <th>Market_Cap_STD</th>\n",
       "      <th>Lagged_Market_Cap</th>\n",
       "      <th>Lagged_VIX_Close</th>\n",
       "      <th>Lagged_S&amp;P500_Close</th>\n",
       "      <th>Crypto_Market_Cap_%</th>\n",
       "      <th>Crypto_Volume_Change_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>2802.4</td>\n",
       "      <td>2805.8</td>\n",
       "      <td>2792.6</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>12.01</td>\n",
       "      <td>12.40</td>\n",
       "      <td>11.62</td>\n",
       "      <td>12.22</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2802.6</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2798.1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>11.18</td>\n",
       "      <td>11.27</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.182316e+11</td>\n",
       "      <td>12.22</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>1.405692</td>\n",
       "      <td>-32.590615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2802.6</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2798.1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>11.18</td>\n",
       "      <td>11.27</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.241106e+11</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>7.716345</td>\n",
       "      <td>-22.683548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2802.6</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>2798.1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>11.18</td>\n",
       "      <td>11.27</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.568364e+11</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>-7.278429</td>\n",
       "      <td>-10.117150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>2809.2</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>2808.1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11.59</td>\n",
       "      <td>11.62</td>\n",
       "      <td>10.84</td>\n",
       "      <td>11.03</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.235859e+11</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2810.3</td>\n",
       "      <td>-4.810684</td>\n",
       "      <td>-4.956410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  S&P500_Close  S&P500_Open  S&P500_High  S&P500_Low  \\\n",
       "0 2018-01-18        2798.0       2802.4       2805.8      2792.6   \n",
       "1 2018-01-19        2810.3       2802.6       2810.3      2798.1   \n",
       "2 2018-01-20        2810.3       2802.6       2810.3      2798.1   \n",
       "3 2018-01-21        2810.3       2802.6       2810.3      2798.1   \n",
       "4 2018-01-22        2833.0       2809.2       2833.0      2808.1   \n",
       "\n",
       "   S&P500_Change_%  VIX_Open  VIX_High  VIX_Low  VIX_Close  ...  Day  \\\n",
       "0            -0.16     12.01     12.40    11.62      12.22  ...   18   \n",
       "1             0.44     12.30     12.33    11.18      11.27  ...   19   \n",
       "2             0.44     12.30     12.33    11.18      11.27  ...   20   \n",
       "3             0.44     12.30     12.33    11.18      11.27  ...   21   \n",
       "4             0.81     11.59     11.62    10.84      11.03  ...   22   \n",
       "\n",
       "   DayOfWeek  IsWeekend  Market_Cap_MA  Market_Cap_STD  Lagged_Market_Cap  \\\n",
       "0          3      False            NaN             NaN                NaN   \n",
       "1          4      False            NaN             NaN       4.182316e+11   \n",
       "2          5       True            NaN             NaN       4.241106e+11   \n",
       "3          6       True            NaN             NaN       4.568364e+11   \n",
       "4          0      False            NaN             NaN       4.235859e+11   \n",
       "\n",
       "   Lagged_VIX_Close  Lagged_S&P500_Close  Crypto_Market_Cap_%  \\\n",
       "0               NaN                  NaN                  NaN   \n",
       "1             12.22               2798.0             1.405692   \n",
       "2             11.27               2810.3             7.716345   \n",
       "3             11.27               2810.3            -7.278429   \n",
       "4             11.27               2810.3            -4.810684   \n",
       "\n",
       "   Crypto_Volume_Change_%  \n",
       "0                     NaN  \n",
       "1              -32.590615  \n",
       "2              -22.683548  \n",
       "3              -10.117150  \n",
       "4               -4.956410  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add all features to the DataFrame\n",
    "main_df = add_seasonal_features(main_df, 'Date')\n",
    "main_df = add_rolling_statistics(main_df, window=7)\n",
    "main_df = add_lag_features(main_df, lag=1)\n",
    "main_df = add_crypto_percent_change(main_df)\n",
    "\n",
    "main_df.to_csv(os.path.join(DATA_PATH, 'MainData_FeatureEngineering.csv'), index=False)\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
